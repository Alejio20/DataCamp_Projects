{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d4387f-fa24-4a80-906b-4cca195b6736",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Recipe Site Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210e4fd-1d04-4460-bad6-f8234b1188d7",
   "metadata": {},
   "source": [
    "# Data Validation\n",
    "### Before data cleaning:\n",
    "The dataset have 947 rows and 8 columns. Some of its columns have missing data.\n",
    "\n",
    "### Columns:\n",
    "* recipe: No missing value. Same as description\n",
    "* calories: Same as description. 52 missing values. Drop row with missing value\n",
    "* carbohydrate: Same as description. 52 missing values. Drop row with missing value\n",
    "* sugar: Same as description. 52 missing values. Drop row with missing value\n",
    "* protein: Same as description. 52 missing values. Drop row with missing value\n",
    "* category: No missing value. Description does not match. Have 11 unique values as opposed to 10. Replace 'Chicken Breast' with 'Chicken'\n",
    "* servings: No missing value. Description does not match. Replace '4 as a snack' with '4' and replace '6 as a snack' with '6'. Convert to integer type\n",
    "* high_traffic: 373 missing values. Fill missing value with 'Low'\n",
    "\n",
    "### After data cleaning:\n",
    "The dataset have 895 rows and 8 columns with no missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4404f40c-60a1-4242-8dbf-2fa725e8f5aa",
   "metadata": {},
   "source": [
    "# Exploratory Analysis: \n",
    "### Nutritional Information:\n",
    "The histograms show that all nutritional information columns are left skewed indicating that majority of their values are in the lowest limit range.\n",
    "![Distribution of Calories](rec1.jpg) \n",
    "![Distribution of Carbohydrate](rec2.jpg)\n",
    "![Distribution of Sugar](rec3.jpg)\n",
    "![Distribution of Protein](rec4.jpg)\n",
    "\n",
    "#### Correlation heatmap of nutritional information:\n",
    "There is generally a weak correlation between all nutritional information columns\n",
    "![Correlation of nutritional information](rec5.jpg)\n",
    "\n",
    "![Relationship between Calories, Carbohydrate, Protein, Sugar](rec6.jpg)\n",
    "\n",
    "### Categorical Variables:\n",
    "Chicken dishes have the highest number of dishes in the category while the remaining with relatively same amount.\n",
    "![Distribution of Category](rec7.jpg)\n",
    "\n",
    "Most dishes in the menu have 4 servings. 1, 2 and 6 servings have relatively similar serving count.\n",
    "![Distribution of servings](rec8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec9f43-38e4-4cf9-b355-912e6b17640d",
   "metadata": {},
   "source": [
    "# Model Development and Evaluation\n",
    "Predicting if a dish is going to be draw high traffic or not is a classification problem in machine learning. I am choosing the K-Nearest Neighbor model as the base model because it takes the majority vote of the closest data points. For the comparison model, I will use the Decision Tree Classifier model because it is easy to interpret and can capture non-linear relationships between features.\n",
    "\n",
    "For the evaluation, I will be using Accuracy to evaluate the model. Accuracy measures the correct prediction per the total oberservation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d8fa9-b4ca-4922-89a5-d1f517f56f5a",
   "metadata": {},
   "source": [
    "### Data Preparation for modeling\n",
    "#### Convert the categorical variables into numeric:\n",
    "![Convert the categorical variables into numeric](rec9.jpg)\n",
    "\n",
    "#### Separate the features and target variable\n",
    "The Target variable is high_traffic column.\n",
    "The feature vaiables I will be using are Calories, Carbohydrate, Protein, Sugar, Category and Servings\n",
    "![Convert the categorical variables into numeric](rec10.jpg)\n",
    "\n",
    "#### Normalize the numeric features\n",
    "![Convert the categorical variables into numeric](rec11.jpg)\n",
    "\n",
    "#### Split the data into training and testing sets\n",
    "![Convert the categorical variables into numeric](rec12.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9441afd-df44-46bd-b2ca-88d9d7bf4079",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor Model\n",
    "![Convert the categorical variables into numeric](rec13.jpg)\n",
    "![Convert the categorical variables into numeric](rec14.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b535638b-e1e7-46d7-9105-61ce4cc84bf0",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier Model\n",
    "![Convert the categorical variables into numeric](rec15.jpg)\n",
    "![Convert the categorical variables into numeric](rec16.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d58021-5abf-433d-995f-57db0e3d49c1",
   "metadata": {},
   "source": [
    "### Result\n",
    "Findings indicate that both models exhibit reasonably good performance, but with slight differences.\n",
    "\n",
    "The base model, which utilizes KNN, achieved an accuracy of approximately 77.1%. KNN is known for its simplicity and intuitive approach, making it a valuable choice for certain datasets and scenarios. However, it may not perform optimally when dealing with high-dimensional or noisy data, as it relies on proximity to neighbors.\n",
    "\n",
    "On the other hand, the comparison model, employing the Decision Tree Classifier, achieved a slightly higher accuracy of around 77.7%. Decision trees are interpretable and can capture complex relationships within the data. They are versatile and perform well on various types of datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e53cd-2b20-44de-9333-60f96ec8a0ae",
   "metadata": {},
   "source": [
    "# Business Metrics\n",
    "### Accuracy: Percentage of Predictions of Recipe with High Traffic\n",
    "This metric evaluates the performance of two predictive models (Decision Tree Classifier and K-Nearest Neighbors - KNN) by measuring the percentage of predictions of recipe with potential high traffic.\n",
    "\n",
    "The results indicate that the Decision Tree Classifier achieved an accuracy of 77.65%, while the KNN model achieved an accuracy of 77.09% in predicting the recipe with potential high traffic. These percentages reflect the models' ability to provide predictions, which can be a valuable metric for assessing their performance in real-world applications.\n",
    "\n",
    "It is important to note that both models didn't achieve 80% prediction but implementing the recommendations might result to an improvement towards achieving that target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b95362-1922-4630-bb10-78e5f082c64d",
   "metadata": {},
   "source": [
    "# Recommendations\n",
    "Based on the performance results provided for the Decision Tree Classifier and K-Nearest Neighbors (KNN) models in predicting high traffic recipe, I recommend the deployment of Decision Tree Classifier into production since it has a slightly better performance and it is interpretable and can capture complex relationships within the data which will be useful for different type of dataset.\n",
    "\n",
    "Here are some recommendations for further improvement:\n",
    "1. Continue to monitor and evaluate the performance of both models over time. Accuracy is an essential metric, but consider other relevant metrics such as precision, recall, and F1-score\n",
    "2. Explore ensemble methods, such as model stacking or voting, that combine the predictions of both models.\n",
    "3. Fine-tune the hyper-parameters of both models further to see if performance can be improved using other fine-tuning techniques\n",
    "4. Assess the importance of features used in the models and consider feature engineering techniques to create new relevant features.\n",
    "5. Ensure data quality and consistency in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5042af-7f73-4808-b735-c262418c9395",
   "metadata": {},
   "source": [
    "## âœ… When you have finished...\n",
    "-  Publish your Workspace using the option on the left\n",
    "-  Check the published version of your report:\n",
    "\t-  Can you see everything you want us to grade?\n",
    "    -  Are all the graphics visible?\n",
    "-  Review the grading rubric. Have you included everything that will be graded?\n",
    "-  Head back to the [Certification Dashboard](https://app.datacamp.com/certification) to submit your practical exam report and record your presentation"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
